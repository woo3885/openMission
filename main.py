"""
FastAPI + LangChain RAG Q&A Bot
2ì£¼ í•´ì»¤í†¤ í”„ë¡œì íŠ¸
"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from dotenv import load_dotenv
import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ í™•ì¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="RAG Q&A Bot API",
    description="LangChainì„ ì‚¬ìš©í•œ ë¬¸ì„œ ê¸°ë°˜ Q&A ì‹œìŠ¤í…œ",
    version="0.1.0"
)

# ë²¡í„° DB ê²½ë¡œ
DB_PATH = "./db"

# 1ï¸âƒ£ Retriever ìƒì„± (ê²€ìƒ‰ê¸°)
# ë””ìŠ¤í¬ì— ì €ì¥ëœ ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì™€ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
vectorstore = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings
)
# retrieverëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤
retriever = vectorstore.as_retriever(
    search_type="similarity",  # ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
    search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ê¸°
)

# 2ï¸âƒ£ Prompt Template ì •ì˜
# ê²€ìƒ‰ëœ ë¬¸ë§¥(context)ê³¼ ì‚¬ìš©ì ì§ˆë¬¸(question)ì„ LLMì— ì „ë‹¬í•˜ëŠ” í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤
template = """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ë¬¸ë§¥(context)ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë§Œì•½ ë¬¸ë§¥ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ë¬¸ë§¥:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

prompt = ChatPromptTemplate.from_template(template)

# 3ï¸âƒ£ LLM ì •ì˜
# GPT-4o ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì •
)

# 4ï¸âƒ£ RAG ì²´ì¸ êµ¬ì„± (LCEL ì‚¬ìš©)
# LCEL(LangChain Expression Language)ë¡œ íŒŒì´í”„ë¼ì¸ì„ ì—°ê²°í•©ë‹ˆë‹¤
# íë¦„: ì§ˆë¬¸ â†’ Retriever(ê²€ìƒ‰) â†’ Prompt â†’ LLM â†’ OutputParser(ê²°ê³¼ ì •ë¦¬)

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©"""
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {
        "context": retriever | format_docs,  # retrieverë¡œ ë¬¸ì„œ ê²€ìƒ‰ í›„ í¬ë§·íŒ…
        "question": RunnablePassthrough()  # ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
    }
    | prompt  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
    | llm  # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
    | StrOutputParser()  # ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ íŒŒì‹±
)


@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "message": "Hello World",
        "status": "running",
        "project": "LangChain RAG Q&A Bot",
        "rag_chain_ready": True
    }


# ğŸ“Œ ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜
class QuestionRequest(BaseModel):
    """ì§ˆë¬¸ ìš”ì²­ ëª¨ë¸"""
    question: str
    
    class Config:
        json_schema_extra = {
            "example": {
                "question": "ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            }
        }


class AnswerResponse(BaseModel):
    """ë‹µë³€ ì‘ë‹µ ëª¨ë¸"""
    question: str
    answer: str


@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """
    ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    - **question**: ì‚¬ìš©ìì˜ ì§ˆë¬¸
    
    Returns:
    - **question**: ì…ë ¥ë°›ì€ ì§ˆë¬¸
    - **answer**: RAG ì²´ì¸ì´ ìƒì„±í•œ ë‹µë³€
    """
    try:
        # RAG ì²´ì¸ ì‹¤í–‰
        # invoke()ëŠ” ë™ê¸° í•¨ìˆ˜ì§€ë§Œ, FastAPIëŠ” ìë™ìœ¼ë¡œ ë¹„ë™ê¸° ì²˜ë¦¬í•©ë‹ˆë‹¤
        answer = rag_chain.invoke(request.question)
        
        return AnswerResponse(
            question=request.question,
            answer=answer
        )
    
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´ ë°˜í™˜
        raise HTTPException(
            status_code=500,
            detail=f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
